---
title: "Marine Genomics"
author:
date: 
output:
  bookdown::html_book:
    toc: yes
    css: toc.css
---


# Awk

`Awk` is a fast and versatile pattern matching programming language. `Awk` can do the same tasks that `sed`, `grep`, `cat`, and `wc`; and then it can do a lot more https://www.gnu.org/software/gawk/manual/gawk.html. This program deserves a full class to go into details, so instead we just have this section to make you aware that the program exists. 

Let's see how awk can behave like `wc`.

```html
$ cd /home/margeno/MarineGenomics/week2/
```

```html
$ ls 

TableS2_QTL_Bay_2017.txt  sra_metadata  untrimmed_fastq
```

This table is from the Bay et al. 2017 publication ~/MarineGenomics/week2/TableS2_QTL_Bay_2017.txt and we will use it as our example file for this section.

We can look inside the file by using `cat` or `awk`

```html 
$ awk '{print $0}' TableS2_QTL_Bay_2017.txt
```

The instructions are enclosed in single quotes

This command has the same output of "cat": it prints each line from the example file TableS2_QTL_Bay_2017.txt

The structure of the instruction is the following:
- curly braces surround the set of instructions
- print is the instruction that sends its arguments to the terminal
- $0 is a variable, it means "the content of the current line"

As you can see, the file contains a table.

```html
Trait 	n	LOD	Chr	Position (cM) 	Nearest SNP 
mate choice	200	4.5	14	22.43	chrXIV:1713227 
mate choice 	200	4.61	21	8	chrXXI:9373717 
discriminant function 	200	4.83	12	17	chrXII:7504339 
discriminant function 	200	4.23	14	8.1	chrXIV:4632223 
PC2	200	4.04	4	30.76	chrIV:11367975 
PC2	200	6.67	7	47	chrVII:26448674 
centroid size	200	6.97	9	47.8	chrIX:19745222 
x2*	200	3.93	7	60	chrUn:29400087 
y2*	200	9.99	4	32	chrIV:11367975 
x3	200	4.45	1	32.3	chrI:15145305 
x4	200	5.13	16	30.9	chrXVI:12111717 
x5*	200	4.54	15	6	chrXV:505537 
y5	200	4.21	4	24.9	chrIV:15721538 
x6	200	3.96	16	29.5	chrXVI:13588796 
y6*	200	4.14	9	30.2	chrIX:18942598 
y15*	200	5.3	2	27	chrII:19324477 
x16	200	5.49	7	60	chrUn:29400087 
x17 	200	4.92	1	32.8	chrI:14261764 
Table S2. Significant QTL loci for mate choice and morphology
``` 

Now let's use `awk` to count the lines of a file, similarly to what `wc -l` would do. 

As you probably remember, -l is an option that asks for the number of lines only.

However, wc counts the number of newlines in the file, if the last line does
not contain a carriage return (i.e. there is no emptyline at the end of the file),
the result is going be the actual number of lines minus one.

```html 
$ wc -l TableS2_QTL_Bay_2017.txt
```

```html
19 TableS2_QTL_Bay_2017.txt
```
	
A workaround is to use `awk`. `Awk` is command line program that takes as input a set
of instructions and one or more files. The instructions are executed on each line
of the input file(s).

```html
$ awk '{print NR;}' TableS2_QTL_Bay_2017.txt | tail -1
```

`Awk` can also search within a file like `grep` can. Let's see if there are any significant QTL loci in the chromosome "chrXIV" 

```html
$ awk '/chrXIV/' TableS2_QTL_Bay_2017.txt
```
This chromosome had two significant QTL Loci for mate choice and morphology. 

</p>
</details>
&nbsp;


When to use awk? 

 *  for search and replacement of large files (it's fast!)
 *  when manipulating multiple large files



## Moving and Downloading Data

Below we'll show you some commands to download data onto your instance, or to move data between your computer and the cloud.

## Getting data from the cloud

There are two programs that will download data from a remote server to your local
(or remote) machine: ``wget`` and ``curl``. They were designed to do slightly different
tasks by default, so you'll need to give the programs somewhat different options to get
the same behaviour, but they are mostly interchangeable.

 - ``wget`` is short for "world wide web get", and it's basic function is to *download*
 web pages or data at a web address.

 - ``cURL`` is a pun, it is supposed to be read as "see URL", so its basic function is
 to *display* webpages or data at a web address.

Which one you need to use mostly depends on your operating system, as most computers will
only have one or the other installed by default.

Today we will use wget to download some data from Ensembl.


<details><summary>Exercise</summary>
<p>

Before we can start our download, we need to know whether we're using ``curl`` or ``wget``.

To see which program you have, type:
 
```html
$ which curl
$ which wget
```


``which`` is a BASH program that looks through everything you have
installed, and tells you what folder it is installed to. If it can't
find the program you asked for, it returns nothing, i.e. gives you no
results.

On Mac OSX, you'll likely get the following output:


```html
$ which wget
```


```html
$ /usr/bin/wget
```

Once you know whether you have ``curl`` or ``wget``, use one of the
following commands to download the file:

</p>
</details>
&nbsp;


```html
$ cd
$ wget ftp://ftp.ensemblgenomes.org/pub/release-37/bacteria/species_EnsemblBacteria.txt
```

Let's see if the file from ensembl downloaded

```html
ls species_EnsemblBacteria.txt
```

it did!


### Uploading and Downloading Data to your Virtual Machine with scp - UNIX

This section is for your general knowledge.

`scp` stands for 'secure copy protocol', and is a widely used UNIX tool for moving files
between computers. The simplest way to use `scp` is to run it in your local terminal,
and use it to copy a single file:

```html
scp <file I want to move> <where I want to move it>
```

In terminal,you can use the `scp` command to upload a file (e.g. local_file.txt) to the cluster home directory:

```html
$  scp local_file.txt UserName@cluster.address:/scratch/
```

If you wanted to download data from your virtual machine, we would put the location of the folder within the virtual machine in the location of <file I want to move>

```html
$  scp UserName@cluster.address:/scratch/VirtualMachine_file.txt /home/margeno/MarineGenomics/week2/untrimmed_fastq/
```

